{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a3a84b3",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<center>Clustering </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e71c9",
   "metadata": {},
   "source": [
    "## Generals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d65503e",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Packages import and system configurations. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3ff6061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import SpectralClustering, KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1939e0",
   "metadata": {},
   "source": [
    "## Data Loading & Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4454d70f",
   "metadata": {},
   "source": [
    "<font size=\"3\">  \n",
    "A function that gives us information about data shapes and reshapes the data in order to be suitable for our models.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "067b7726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reshape(x_train,y_train,x_test,y_test):\n",
    "    print ('Basic informations:')\n",
    "    print('X_train: ' + str(x_train.shape))\n",
    "    print('Y_train: ' + str(y_train.shape))\n",
    "    print('X_test:  ' + str(x_test.shape))\n",
    "    print('Y_test:  ' + str(y_test.shape))\n",
    "    x_train = x_train.reshape(x_train.shape[0], np.prod(x_train.shape[1:])) \n",
    "    x_test = x_test.reshape(x_test.shape[0], np.prod(x_test.shape[1:]))  \n",
    "    # Change integers to 32-bit floating point numbers\n",
    "    x_train = x_train.astype('float32')   \n",
    "    x_test = x_test.astype('float32')\n",
    "    print(\"\\nData shapes after reshaping:\")\n",
    "    print(\"Training matrix shape\", x_train.shape)\n",
    "    print(\"Testing matrix shape\", x_test.shape)\n",
    "    return x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32303139",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "A function that provides us with the input data:\n",
    "<ol>\n",
    "<li>Load the necessary data according to the give to the given data name.</li>\n",
    "<li>Create a subset for each data according to the given data sizes (If subset variable = 'True\").</li>\n",
    "<li>Use the above function and returns the reshaped data.</li>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "580479db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(subset,train_subset_size,test_subset_size):\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    if subset:\n",
    "        x_train,y_train,x_test,y_test = x_train[:train_subset_size],y_train[:train_subset_size],x_test[:test_subset_size],y_test[:test_subset_size]\n",
    "        x_train,y_train,x_test,y_test = data_reshape(x_train,y_train,x_test,y_test)\n",
    "    else:\n",
    "        x_train,y_train,x_test,y_test = data_reshape(x_train,y_train,x_test,y_test)\n",
    "        \n",
    "    return x_train,y_train,x_test,y_test   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c4088",
   "metadata": {},
   "source": [
    "<font size=\"3\">  \n",
    "A function that applies standardization on the given data and returns it.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "187ff5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalling(x_train,x_test):\n",
    "    x_train = StandardScaler().fit_transform(x_train)\n",
    "    x_test = StandardScaler().fit_transform(x_test)\n",
    "    return x_train,x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a921c2",
   "metadata": {},
   "source": [
    "<font size=\"3\">  \n",
    "A function that aplly clustering with the given method and with the given k and returns the silhouette score\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa704f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_pipeline(data_input,method,k):\n",
    "    if method == 'K-Means':\n",
    "        cluster_alg = KMeans(n_clusters=k)\n",
    "    elif method == 'Spectral-Clustering':\n",
    "        cluster_alg = SpectralClustering(n_clusters=k, affinity='nearest_neighbors', random_state=0)\n",
    "    \n",
    "    clustering = cluster_alg.fit(data_input)\n",
    "    cluster_assignments = clustering.labels_\n",
    "    silhouette = silhouette_score(data_input,cluster_assignments)  \n",
    "    return silhouette"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b6706",
   "metadata": {},
   "source": [
    "<font size=\"3\">  \n",
    "A function that runs all the experiments using a for loop\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a71ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_experiments(data_input,method,n_clusters):\n",
    "    all_results = []\n",
    "    for k in n_clusters:\n",
    "        silhouette = cluster_pipeline(data_input,method,k)\n",
    "        experiment = []\n",
    "        experiment.append(method)\n",
    "        experiment.append(k)\n",
    "        experiment.append(silhouette)\n",
    "        print ('Algorithm: ',experiment[0],', K:',experiment[1],', Silhouette Score:',experiment[2])\n",
    "        all_results.append(experiment)     \n",
    "    return all_results    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f24a97",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3d4402",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "In the following cells we use the above functions to apply clustering algorithms to a subset of Mnist-dataset.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c16409a",
   "metadata": {},
   "source": [
    "### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97f99969",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset_size = 5000\n",
    "test_subset_size = 2000\n",
    "different_k = np.arange(6,16,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9dcc8c",
   "metadata": {},
   "source": [
    "### Data Loading, Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c34e1b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic informations:\n",
      "X_train: (5000, 28, 28)\n",
      "Y_train: (5000,)\n",
      "X_test:  (2000, 28, 28)\n",
      "Y_test:  (2000,)\n",
      "\n",
      "Data shapes after reshaping:\n",
      "Training matrix shape (5000, 784)\n",
      "Testing matrix shape (2000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test  = data_load(True,train_subset_size,test_subset_size)\n",
    "x_train,x_test = scalling(x_train,x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460b448b",
   "metadata": {},
   "source": [
    "### EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3552793d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm:  K-Means , K: 6 , Silhouette Score: 0.0140361\n",
      "Algorithm:  K-Means , K: 7 , Silhouette Score: 0.011110065\n",
      "Algorithm:  K-Means , K: 8 , Silhouette Score: 0.008026962\n",
      "Algorithm:  K-Means , K: 9 , Silhouette Score: 0.027330102\n",
      "Algorithm:  K-Means , K: 10 , Silhouette Score: 0.014517139\n",
      "Algorithm:  K-Means , K: 11 , Silhouette Score: 0.012568094\n",
      "Algorithm:  K-Means , K: 12 , Silhouette Score: 0.01579247\n",
      "Algorithm:  K-Means , K: 13 , Silhouette Score: -0.010654097\n",
      "Algorithm:  K-Means , K: 14 , Silhouette Score: -0.005366548\n",
      "Algorithm:  K-Means , K: 15 , Silhouette Score: 0.003461831\n",
      "\n",
      "\n",
      "Algorithm:  Spectral-Clustering , K: 6 , Silhouette Score: 0.057583276\n",
      "Algorithm:  Spectral-Clustering , K: 7 , Silhouette Score: -0.07768214\n",
      "Algorithm:  Spectral-Clustering , K: 8 , Silhouette Score: -0.0713104\n",
      "Algorithm:  Spectral-Clustering , K: 9 , Silhouette Score: -0.06938579\n",
      "Algorithm:  Spectral-Clustering , K: 10 , Silhouette Score: -0.06417128\n",
      "Algorithm:  Spectral-Clustering , K: 11 , Silhouette Score: -0.056199\n",
      "Algorithm:  Spectral-Clustering , K: 12 , Silhouette Score: -0.05167002\n",
      "Algorithm:  Spectral-Clustering , K: 13 , Silhouette Score: -0.042212114\n",
      "Algorithm:  Spectral-Clustering , K: 14 , Silhouette Score: -0.036729522\n",
      "Algorithm:  Spectral-Clustering , K: 15 , Silhouette Score: -0.051871266\n"
     ]
    }
   ],
   "source": [
    "all_results = k_experiments(x_train,'K-Means',different_k)\n",
    "print ('\\n')\n",
    "all_results = k_experiments(x_train,'Spectral-Clustering',different_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe20e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full_ml",
   "language": "python",
   "name": "full_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
