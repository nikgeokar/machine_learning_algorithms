{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01db6270",
   "metadata": {},
   "source": [
    "# MODEL EVALUATION + FRIEDMAN TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25bc3a",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7ff8b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from itertools import combinations\n",
    "import pingouin as pg\n",
    "import scikit_posthocs as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e12148",
   "metadata": {},
   "source": [
    "### Leave one out cross valiadation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5df29dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_LeaveOneOut(X,y):\n",
    "    cv = LeaveOneOut()\n",
    "    # enumerate splits\n",
    "    y_true, y_pred = list(), list()\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        # split data\n",
    "        X_train, X_test = X[train_ix, :], X[test_ix, :]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        # fit model\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        # evaluate model\n",
    "        yhat = model.predict(X_test)\n",
    "        # store\n",
    "        y_true.append(y_test[0])\n",
    "        y_pred.append(yhat[0])\n",
    "    # calculate accuracy\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print('Accuracy Score: %.3f' % acc)\n",
    "    return acc,y_true,y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c829541",
   "metadata": {},
   "source": [
    "### Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ff0aa8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "    print ('True Positive :',TP)\n",
    "    print ('True Negative :',TN)  \n",
    "    print ('False Positive :',FP)  \n",
    "    print ('False Negative :',FN)\n",
    "    \n",
    "    return TP, FP, TN, FN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fdda58",
   "metadata": {},
   "source": [
    "### All merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "04842f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 1.000\n",
      "True Positive : 33\n",
      "True Negative : 34\n",
      "False Positive : 0\n",
      "False Negative : 0\n"
     ]
    }
   ],
   "source": [
    "X,y = make_blobs(n_samples=100, random_state=42)\n",
    "acc,y_true,y_pred = apply_LeaveOneOut(X,y)\n",
    "TP,FP,TN,FN = perf_measure(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d26a9b0",
   "metadata": {},
   "source": [
    "### Friedman Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9b7183f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def friedman_test(algo_performance,a_list):\n",
    "    for alpha in a_list:\n",
    "        results = pg.friedman(data=algo_performance)\n",
    "        q, p = results['Q'].values.tolist()[0], results['p-unc'].values.tolist()[0]\n",
    "        print(f\"Q={round(q,3)}, p={p}\")\n",
    "        # interpret\n",
    "        print ('With alpha = ',alpha)\n",
    "        if p > alpha:\n",
    "            # They dont have statistically significant differences between them\n",
    "            print('Test Result: Same distributions\\n')\n",
    "        else:\n",
    "            # They have statistically significant differences between them\n",
    "            print('Test Result: Different distributions\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f100c5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRIEDMAN TEST:\n",
      "Q=39.913, p=4.512033059024903e-08\n",
      "With alpha =  0.001\n",
      "Test Result: Different distributions\n",
      "\n",
      "Q=39.913, p=4.512033059024903e-08\n",
      "With alpha =  0.005\n",
      "Test Result: Different distributions\n",
      "\n",
      "Q=39.913, p=4.512033059024903e-08\n",
      "With alpha =  0.01\n",
      "Test Result: Different distributions\n",
      "\n",
      "Q=39.913, p=4.512033059024903e-08\n",
      "With alpha =  0.05\n",
      "Test Result: Different distributions\n",
      "\n",
      "Q=39.913, p=4.512033059024903e-08\n",
      "With alpha =  0.1\n",
      "Test Result: Different distributions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names=['C4.5','1-NN','NaiveBayes','Kernel','CN2']\n",
    "a_list = [0.001,0.005,0.01,0.05,0.1]\n",
    "algo_performance = pd.read_csv('algo_performance.csv',sep=',',index_col=0)\n",
    "algo_performance = algo_performance.reset_index(level=0)\n",
    "print ('FRIEDMAN TEST:')\n",
    "friedman_test(algo_performance,a_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebef953",
   "metadata": {},
   "source": [
    "### Nemenyi Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2e4002c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NEMENYI TEST:\n",
      "ALGORITHMS ADJACENCY MATRIX OF P VALUES\n",
      "                C4.5      1-NN  NaiveBayes    Kernel       CN2\n",
      "C4.5        1.000000  0.450299    0.979836  0.001110  0.727846\n",
      "1-NN        0.450299  1.000000    0.809691  0.237537  0.993329\n",
      "NaiveBayes  0.979836  0.809691    1.000000  0.011000  0.963403\n",
      "Kernel      0.001110  0.237537    0.011000  1.000000  0.089031\n",
      "CN2         0.727846  0.993329    0.963403  0.089031  1.000000\n"
     ]
    }
   ],
   "source": [
    "print('\\nNEMENYI TEST:') \n",
    "print('ALGORITHMS ADJACENCY MATRIX OF P VALUES')\n",
    "results = sp.posthoc_nemenyi(np.array(algo_performance.T)).values.tolist()\n",
    "results = pd.DataFrame(results,columns=names,index=names)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26ce4fe",
   "metadata": {},
   "source": [
    "Είναι προφανές πως οι αλγόριθμοι έχουν μεταξύ τους στατιστικά σημαντικές διαφορές.\n",
    "Αυτό αποδείχθηκε από το Friedman test για όλα τα alpha που δοκιμάστηκαν.\n",
    "Το παραπάνω συμπέρασμα αποδείχθηκε επίσης από το Nemenyi Test. Όπου είναι ξεκάθαρο πως τα παρακάτω ζευγάρια αλγορίθμων έχουν μεταξύ τους στατιστικά σημαντικές διαφορές (a = 0.01)\n",
    "1) Kernel - C4.5\n",
    "\n",
    "2) NaiveBayes - Kernel\n",
    "\n",
    "3) Kernel & CN2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4acccae",
   "metadata": {},
   "source": [
    "### Pairwise Friedman Test of Algorithms (a = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09543d48",
   "metadata": {},
   "source": [
    "Παραπάνω αποδείξαμε πριν με το  Nemenyi Test oτι κάποια συγκεκριμένα ζευγάρια αλγορίθμων έχουν μεταξύ τους σημαντικές στατιστικές διαφορές.\n",
    "Παρακάτω αποδεικνύουμε την ενλόγω υπόθεση και με το Friedman Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "14972c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def friedman_test_sep(algo_performance,all_pairs):\n",
    "    for names in all_pairs:\n",
    "        results = pg.friedman(data=algo_performance[list(names)])\n",
    "        q, p = results['Q'].values.tolist()[0], results['p-unc'].values.tolist()[0]\n",
    "        print('Algorithms = ', names[0], '&', names[1])\n",
    "        print(f\"Q={round(q,3)}, p={p}\")\n",
    "        # interpret\n",
    "        if p > 0.001:\n",
    "            # They dont have statistically significant differences between them\n",
    "            print('Test Result: Same distributions\\n')\n",
    "        else:\n",
    "            # They have statistically significant differences between them\n",
    "            print('Test Result: Different distributions\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5cfec74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithms =  C4.5 & 1-NN\n",
      "Q=7.759, p=0.005345676872654246\n",
      "Test Result: Same distributions\n",
      "\n",
      "Algorithms =  C4.5 & NaiveBayes\n",
      "Q=0.133, p=0.7150006546880892\n",
      "Test Result: Same distributions\n",
      "\n",
      "Algorithms =  C4.5 & Kernel\n",
      "Q=19.2, p=1.1771339097615013e-05\n",
      "Test Result: Different distributions\n",
      "\n",
      "Algorithms =  C4.5 & CN2\n",
      "Q=9.966, p=0.0015949936169505205\n",
      "Test Result: Same distributions\n",
      "\n",
      "Algorithms =  1-NN & NaiveBayes\n",
      "Q=4.8, p=0.028459736916310617\n",
      "Test Result: Same distributions\n",
      "\n",
      "Algorithms =  1-NN & Kernel\n",
      "Q=8.533, p=0.003487004892141391\n",
      "Test Result: Same distributions\n",
      "\n",
      "Algorithms =  1-NN & CN2\n",
      "Q=0.533, p=0.4652088184521417\n",
      "Test Result: Same distributions\n",
      "\n",
      "Algorithms =  NaiveBayes & Kernel\n",
      "Q=13.333, p=0.00026072963285531705\n",
      "Test Result: Different distributions\n",
      "\n",
      "Algorithms =  NaiveBayes & CN2\n",
      "Q=7.0, p=0.008150971593502695\n",
      "Test Result: Same distributions\n",
      "\n",
      "Algorithms =  Kernel & CN2\n",
      "Q=13.333, p=0.00026072963285531705\n",
      "Test Result: Different distributions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_pairs = list(combinations(names, 2))\n",
    "friedman_test_sep(algo_performance,all_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abca2554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full_ml",
   "language": "python",
   "name": "full_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
